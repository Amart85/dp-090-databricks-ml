---
lab:
    title: 'Working with Data in Azure Databricks'
---
# Working with Data in Azure Databricks

You will learn to load your data by using DBFS and manipulate it by using Spark Dataframes.
Databricks File System (DBFS) is a distributed file system mounted into a Databricks workspace and available on Databricks clusters.
DataFrames are the distributed collections of data allowing the processing of huge amounts of data.

## Unit Pre-requisites

Assuming you have completed the previous lab, you have a working setup already. A cluster is available and your workspace exists.

Also, the notebook and the required data has been already imported.

## Exercise: Working with Data in Azure Databricks

In this exercise, you will learn how to load and manipulate data inside the Azure Databricks environment.

1. Within the Azure Databricks Workspace, using the command bar on the left, select **Workspace**, **Users** and select your username (the entry with house icon). Open the notebook named **Working with data in Azure Databricks**.

2. Then read the notes in the notebook, running each code cell in turn.  

## Clean-up

If you're finished working with Azure Databricks for now, in Azure Databricks workspace, on the **Clusters** page, select your cluster and select **Terminate** to shut it down. Otherwise, leave it running for the next exercise.
